{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import math\n",
    "from reader import InHospitalMortalityReader, PhenotypingReader, LengthOfStayReader, DecompensationReader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resources/channel_info.json') as f:\n",
    "    series_channel_info = json.load(f)\n",
    "\n",
    "with open('resources/discretizer_config.json') as f:\n",
    "    series_config = json.load(f)\n",
    "    id_to_channel = series_config['id_to_channel']\n",
    "    is_categorical_channel = series_config['is_categorical_channel']\n",
    "    normal_values = series_config['normal_values']\n",
    "    possible_values = series_config['possible_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_chunk(reader, chunk_size):\n",
    "    data = {}\n",
    "    for i in range(chunk_size):\n",
    "        ret = reader.read_next()\n",
    "        for k, v in ret.items():\n",
    "            if k not in data:\n",
    "                data[k] = []\n",
    "            data[k].append(v)\n",
    "    data[\"header\"] = data[\"header\"][0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_length = 48\n",
    "path = 'in-hospital-mortality'\n",
    "\n",
    "data_all = []\n",
    "mask_all = []\n",
    "label_all = []\n",
    "name_all = []\n",
    "for mode in ['train', 'val', 'test']:\n",
    "    reader = InHospitalMortalityReader(dataset_dir=os.path.join(path, 'train' if mode != 'test' else 'test'),\n",
    "            listfile=os.path.join(path, mode + '_listfile.csv'), period_length=period_length)\n",
    "    N = reader.get_number_of_examples()\n",
    "    ret = read_chunk(reader, N)\n",
    "    data = ret[\"X\"]\n",
    "    ts = ret[\"t\"]\n",
    "    labels = ret[\"y\"]\n",
    "    names = ret[\"name\"]\n",
    "    label_all += labels\n",
    "    name_all += names\n",
    "    for patient, name in zip(data, names):\n",
    "        data_patient = np.zeros(shape=(len(id_to_channel), period_length), dtype=np.float32)\n",
    "        mask_patient = np.zeros(shape=(len(id_to_channel), period_length), dtype=np.float32)\n",
    "        last_time = -1\n",
    "        for row in patient:\n",
    "            time = int(float(row[0]))\n",
    "            if time == period_length:\n",
    "                time -= 1\n",
    "            if time > period_length:\n",
    "                raise ValueError('This should not happen')\n",
    "                break\n",
    "            for index in range(len(row) - 1):\n",
    "                value = row[index + 1]\n",
    "                if value == '':\n",
    "                    # continue\n",
    "                    if mask_patient[index, time] == 0 and time - last_time > 0:\n",
    "                        if last_time >= 0:\n",
    "                            data_patient[index, last_time + 1:time + 1] = data_patient[index, last_time]\n",
    "                        else:\n",
    "                            if is_categorical_channel[id_to_channel[index]]:\n",
    "                                data_patient[index, last_time + 1:time + 1] = series_channel_info[id_to_channel[index]]['values'][normal_values[id_to_channel[index]]]\n",
    "                            else:\n",
    "                                data_patient[index, last_time + 1:time + 1] = float(normal_values[id_to_channel[index]])\n",
    "                else:\n",
    "                    mask_patient[index, time] = 1\n",
    "                    if is_categorical_channel[id_to_channel[index]]:\n",
    "                        data_patient[index, time] = series_channel_info[id_to_channel[index]]['values'][value]\n",
    "                    else:\n",
    "                        data_patient[index, time] = float(value)\n",
    "            last_time = time\n",
    "        if last_time < period_length - 1:\n",
    "            data_patient[:, last_time + 1:period_length] = data_patient[:, last_time, None]\n",
    "        data_all.append(data_patient.transpose(-1, -2))\n",
    "        mask_all.append(mask_patient.transpose(-1, -2))\n",
    "print(len(data_all), len(mask_all), len(label_all), len(name_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21139, 48, 17)\n",
      "[0.13342736248236953 61.46879638121556 0.5394284355238489\n",
      " 3.119246761936625 5.290596950448792 11.61723736264916 3.180522838632143\n",
      " 143.22674480392305 86.3000568382371 168.72015948168453 78.73798307306927\n",
      " 97.69934906068663 19.29756913160995 120.31029497386514 37.0390698629806\n",
      " 83.27462812014336 7.282118883324198] [0.34003602959594353 250.38515121981368 0.20068257457910565\n",
      " 1.262228263075122 1.404701993389681 3.9093606844685147 1.897389901895581\n",
      " 69.23859216770816 19.169864801840426 15.020152083998529 154.8090453358367\n",
      " 1030.9393550934726 6.63088371639584 25.232502325232193 9.535566627978861\n",
      " 26.058995236709116 2.217256925266793]\n"
     ]
    }
   ],
   "source": [
    "data_all = np.array(data_all)\n",
    "mask_all = np.array(mask_all)\n",
    "data_all_concat = np.concatenate(data_all, axis=0)\n",
    "x_masked = np.ma.masked_array(data_all_concat, np.concatenate(mask_all, axis=0) == 0)\n",
    "mean = np.mean(x_masked, 0)\n",
    "std = np.std(x_masked, 0)\n",
    "print(mean, std)\n",
    "data_normalized = np.where(mask_all == 1, (data_all - mean.reshape(1, 1, -1)) / std.reshape(1, 1, -1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump((data_all.tolist(), label_all, np.array(), mask_all.tolist(), name_all), open('mortality.pkl', 'wb'))\n",
    "pickle.dump((data_normalized.tolist(), label_all, mask_all.tolist(), name_all), open('mortality_normalized.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Rate: 0.433020198239663\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "cnt1 = 0\n",
    "for i in range(len(mask_all)):\n",
    "    for j in range(len(mask_all[i])):\n",
    "        cnt += sum(mask_all[i][j])\n",
    "        cnt1 += len(mask_all[i][j])\n",
    "print('Observed Rate:', cnt / cnt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13231467902928237"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(label_all) / len(label_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_length = 48\n",
    "path = 'phenotyping'\n",
    "\n",
    "data_all = []\n",
    "mask_all = []\n",
    "label_all = []\n",
    "name_all = []\n",
    "for mode in ['train', 'val', 'test']:\n",
    "    reader = PhenotypingReader(dataset_dir=os.path.join(path, 'train' if mode != 'test' else 'test'),\n",
    "            listfile=os.path.join(path, mode + '_listfile.csv'))\n",
    "    N = reader.get_number_of_examples()\n",
    "    ret = read_chunk(reader, N)\n",
    "    data = ret[\"X\"]\n",
    "    ts = ret[\"t\"]\n",
    "    labels = ret[\"y\"]\n",
    "    names = ret[\"name\"]\n",
    "    label_all += labels\n",
    "    name_all += names\n",
    "    for patient, name, t in tqdm(zip(data, names, ts), total=len(data)):\n",
    "        N_bins = min(int(t + 1 - 1e-6), period_length)\n",
    "        data_patient = np.zeros(shape=(len(id_to_channel), N_bins), dtype=np.float32)\n",
    "        mask_patient = np.zeros(shape=(len(id_to_channel), N_bins), dtype=np.float32)\n",
    "        last_time = -1\n",
    "        for row in patient:\n",
    "            time = int(float(row[0]))\n",
    "            if time == N_bins:\n",
    "                time -= 1\n",
    "            if time > N_bins:\n",
    "                # raise ValueError('This should not happen')\n",
    "                break\n",
    "            for index in range(len(row) - 1):\n",
    "                value = row[index + 1]\n",
    "                if value == '':\n",
    "                    if mask_patient[index, time] == 0 and time - last_time > 0:\n",
    "                        # if last_time >= 0:\n",
    "                        #     data_patient[index, last_time + 1:time + 1] = data_patient[index, last_time]\n",
    "                        # else:\n",
    "                        if is_categorical_channel[id_to_channel[index]]:\n",
    "                            data_patient[index, last_time + 1:time + 1] = series_channel_info[id_to_channel[index]]['values'][normal_values[id_to_channel[index]]]\n",
    "                        else:\n",
    "                            data_patient[index, last_time + 1:time + 1] = float(normal_values[id_to_channel[index]])\n",
    "                else:\n",
    "                    mask_patient[index, time] += 1\n",
    "                    if is_categorical_channel[id_to_channel[index]]:\n",
    "                        data_patient[index, time] += series_channel_info[id_to_channel[index]]['values'][value]\n",
    "                    else:\n",
    "                        data_patient[index, time] += float(value)\n",
    "            last_time = time\n",
    "        data_patient = np.where(mask_patient > 0, data_patient / mask_patient, data_patient)\n",
    "        mask_patient = np.where(mask_patient > 0, 1, 0)\n",
    "        # assert np.count_nonzero(data_patient == np.nan) == 0\n",
    "        data_all.append(data_patient.transpose(-1, -2))\n",
    "        mask_all.append(mask_patient.transpose(-1, -2))\n",
    "print(len(data_all), len(mask_all), len(label_all), len(name_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_bins = 0\n",
    "ts = []\n",
    "label_all = []\n",
    "for mode in ['train', 'val', 'test']:\n",
    "    reader = PhenotypingReader(dataset_dir=os.path.join(path, 'train' if mode != 'test' else 'test'),\n",
    "            listfile=os.path.join(path, mode + '_listfile.csv'))\n",
    "    N = reader.get_number_of_examples()\n",
    "    ret = read_chunk(reader, N)\n",
    "    data = ret[\"X\"]\n",
    "    ts += ret[\"t\"]\n",
    "    labels = ret[\"y\"]\n",
    "    label_all += labels\n",
    "print(ts)\n",
    "label_all = np.array(label_all)\n",
    "print(np.sum(label_all) / len(label_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.52940027e-04 6.57730408e+01 2.25078121e-01 3.93079996e+00\n",
      " 6.04431057e+00 1.43859215e+01 4.74529743e+00 1.34997192e+02\n",
      " 9.01411362e+01 1.66275803e+02 8.40404968e+01 1.02522522e+02\n",
      " 2.07139950e+01 1.28963440e+02 3.74240494e+01 8.24912872e+01\n",
      " 7.47933054e+00] [1.87711418e-02 2.13222717e+02 1.11536264e-01 1.38611352e+00\n",
      " 2.04904175e+00 3.90546131e+00 1.78289831e+00 2.66230988e+02\n",
      " 3.87443848e+01 2.92791004e+01 1.20651512e+02 7.68572571e+02\n",
      " 9.21587463e+02 1.61897217e+02 1.20404739e+01 3.22362085e+03\n",
      " 2.04241657e+00]\n",
      "Observed Rate: 0.41815378281625576\n"
     ]
    }
   ],
   "source": [
    "data_all_concat = np.concatenate(data_all, axis=0)\n",
    "mean = np.mean(data_all_concat, 0)\n",
    "std = np.std(data_all_concat, 0)\n",
    "print(mean, std)\n",
    "data_normalized = [((data - mean.reshape(1, -1)) / std.reshape(1, -1)).tolist() for data in data_all]\n",
    "mask_all = [mask.tolist() for mask in mask_all]\n",
    "\n",
    "pickle.dump((data_normalized, label_all, mask_all, name_all), open('phenotyping_normalized.pkl', 'wb'))\n",
    "\n",
    "cnt = 0\n",
    "cnt1 = 0\n",
    "for i in range(len(mask_all)):\n",
    "    for j in range(len(mask_all[i])):\n",
    "        cnt += sum(mask_all[i][j])\n",
    "        cnt1 += len(mask_all[i][j])\n",
    "print('Observed Rate:', cnt / cnt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29143 [00:00<?, ?it/s]/tmp/ipykernel_16488/268590032.py:49: RuntimeWarning: divide by zero encountered in divide\n",
      "  data_patient = np.where(mask_patient > 0, data_patient / mask_patient, data_patient)\n",
      "/tmp/ipykernel_16488/268590032.py:49: RuntimeWarning: invalid value encountered in divide\n",
      "  data_patient = np.where(mask_patient > 0, data_patient / mask_patient, data_patient)\n",
      "100%|██████████| 29143/29143 [01:27<00:00, 334.03it/s]\n",
      "100%|██████████| 6346/6346 [00:18<00:00, 338.37it/s]\n",
      "100%|██████████| 6255/6255 [00:18<00:00, 332.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41744 41744 41744 41744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "period_length = 24\n",
    "path = 'decompensation'\n",
    "\n",
    "data_all = []\n",
    "mask_all = []\n",
    "label_all = []\n",
    "name_all = []\n",
    "for mode in ['train', 'val', 'test']:\n",
    "    reader = DecompensationReader(dataset_dir=os.path.join(path, 'train' if mode != 'test' else 'test'),\n",
    "            listfile=os.path.join(path, mode + '_listfile.csv'))\n",
    "    N = reader.get_number_of_examples()\n",
    "    ret = read_chunk(reader, N)\n",
    "    data = ret[\"X\"]\n",
    "    ts = ret[\"t\"]\n",
    "    labels = ret[\"y\"]\n",
    "    names = ret[\"name\"]\n",
    "    label_all += labels\n",
    "    name_all += names\n",
    "    for patient, name, t in tqdm(zip(data, names, ts), total=len(data)):\n",
    "        N_bins = min(int(t + 1 - 1e-6), period_length)\n",
    "        data_patient = np.zeros(shape=(len(id_to_channel), N_bins), dtype=np.float32)\n",
    "        mask_patient = np.zeros(shape=(len(id_to_channel), N_bins), dtype=np.float32)\n",
    "        last_time = -1\n",
    "        for row in patient:\n",
    "            time = int(float(row[0]))\n",
    "            if time == N_bins:\n",
    "                time -= 1\n",
    "            if time > N_bins:\n",
    "                # raise ValueError('This should not happen')\n",
    "                break\n",
    "            for index in range(len(row) - 1):\n",
    "                value = row[index + 1]\n",
    "                if value == '':\n",
    "                    if mask_patient[index, time] == 0 and time - last_time > 0:\n",
    "                        # if last_time >= 0:\n",
    "                        #     data_patient[index, last_time + 1:time + 1] = data_patient[index, last_time]\n",
    "                        # else:\n",
    "                        if is_categorical_channel[id_to_channel[index]]:\n",
    "                            data_patient[index, last_time + 1:time + 1] = series_channel_info[id_to_channel[index]]['values'][normal_values[id_to_channel[index]]]\n",
    "                        else:\n",
    "                            data_patient[index, last_time + 1:time + 1] = float(normal_values[id_to_channel[index]])\n",
    "                else:\n",
    "                    mask_patient[index, time] += 1\n",
    "                    if is_categorical_channel[id_to_channel[index]]:\n",
    "                        data_patient[index, time] += series_channel_info[id_to_channel[index]]['values'][value]\n",
    "                    else:\n",
    "                        data_patient[index, time] += float(value)\n",
    "            last_time = time\n",
    "        data_patient = np.where(mask_patient > 0, data_patient / mask_patient, data_patient)\n",
    "        mask_patient = np.where(mask_patient > 0, 1, 0)\n",
    "        # assert np.count_nonzero(data_patient == np.nan) == 0\n",
    "        data_all.append(data_patient.transpose(-1, -2))\n",
    "        mask_all.append(mask_patient.transpose(-1, -2))\n",
    "print(len(data_all), len(mask_all), len(label_all), len(name_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.6462824e-04 6.7509583e+01 2.3202808e-01 4.0216231e+00 6.1931319e+00\n",
      " 1.4663564e+01 4.8571868e+00 1.3957463e+02 9.2549011e+01 1.6925241e+02\n",
      " 8.6117294e+01 1.0576494e+02 2.1513866e+01 1.3186606e+02 3.8373699e+01\n",
      " 8.1611977e+01 7.6491199e+00] [1.9084949e-02 1.9184895e+02 1.1985364e-01 1.3376771e+00 1.9729450e+00\n",
      " 3.5173326e+00 1.7233016e+00 3.4439746e+02 3.7673790e+01 2.2092722e+01\n",
      " 1.2524643e+02 1.0012802e+03 1.2013160e+03 1.4728951e+02 1.1425072e+01\n",
      " 1.7897316e+01 2.0367055e+00]\n",
      "Observed Rate: 0.4313917233395309\n"
     ]
    }
   ],
   "source": [
    "data_all_concat = np.concatenate(data_all, axis=0)\n",
    "mean = np.mean(data_all_concat, 0)\n",
    "std = np.std(data_all_concat, 0)\n",
    "print(mean, std)\n",
    "data_normalized = [((data - mean.reshape(1, -1)) / std.reshape(1, -1)).tolist() for data in data_all]\n",
    "mask_all = [mask.tolist() for mask in mask_all]\n",
    "\n",
    "pickle.dump((data_normalized, label_all, mask_all, name_all), open('decompensation_normalized.pkl', 'wb'))\n",
    "\n",
    "cnt = 0\n",
    "cnt1 = 0\n",
    "for i in range(len(mask_all)):\n",
    "    for j in range(len(mask_all[i])):\n",
    "        cnt += sum(mask_all[i][j])\n",
    "        cnt1 += len(mask_all[i][j])\n",
    "print('Observed Rate:', cnt / cnt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.035310463779225754"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(label_all) / len(label_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'decompensation'\n",
    "max_bins = 0\n",
    "ts = []\n",
    "label_all = []\n",
    "for mode in ['train', 'val', 'test']:\n",
    "    reader = DecompensationReader(dataset_dir=os.path.join(path, 'train' if mode != 'test' else 'test'),\n",
    "            listfile=os.path.join(path, mode + '_listfile.csv'))\n",
    "    N = reader.get_number_of_examples()\n",
    "    ret = read_chunk(reader, N)\n",
    "    data = ret[\"X\"]\n",
    "    ts += ret[\"t\"]\n",
    "    labels = ret[\"y\"]\n",
    "    label_all += labels\n",
    "print(ts)\n",
    "label_all = np.array(label_all)\n",
    "print(np.sum(label_all) / len(label_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23220 [00:00<?, ?it/s]/tmp/ipykernel_48397/1823644643.py:49: RuntimeWarning: divide by zero encountered in divide\n",
      "  data_patient = np.where(mask_patient > 0, data_patient / mask_patient, data_patient)\n",
      "/tmp/ipykernel_48397/1823644643.py:49: RuntimeWarning: invalid value encountered in divide\n",
      "  data_patient = np.where(mask_patient > 0, data_patient / mask_patient, data_patient)\n",
      "100%|██████████| 23220/23220 [01:14<00:00, 312.41it/s]\n",
      "100%|██████████| 5106/5106 [00:16<00:00, 311.23it/s]\n",
      "100%|██████████| 5034/5034 [00:16<00:00, 304.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33360 33360 33360 33360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "period_length = 24\n",
    "path = 'length-of-stay'\n",
    "\n",
    "data_all = []\n",
    "mask_all = []\n",
    "label_all = []\n",
    "name_all = []\n",
    "for mode in ['train', 'val', 'test']:\n",
    "    reader = LengthOfStayReader(dataset_dir=os.path.join(path, 'train' if mode != 'test' else 'test'),\n",
    "            listfile=os.path.join(path, mode + '_listfile.csv'))\n",
    "    N = reader.get_number_of_examples()\n",
    "    ret = read_chunk(reader, N)\n",
    "    data = ret[\"X\"]\n",
    "    ts = ret[\"t\"]\n",
    "    labels = ret[\"y\"]\n",
    "    names = ret[\"name\"]\n",
    "    label_all += labels\n",
    "    name_all += names\n",
    "    for patient, name, t in tqdm(zip(data, names, ts), total=len(data)):\n",
    "        N_bins = min(int(t + 1 - 1e-6), period_length)\n",
    "        data_patient = np.zeros(shape=(len(id_to_channel), N_bins), dtype=np.float32)\n",
    "        mask_patient = np.zeros(shape=(len(id_to_channel), N_bins), dtype=np.float32)\n",
    "        last_time = -1\n",
    "        for row in patient:\n",
    "            time = int(float(row[0]))\n",
    "            if time == N_bins:\n",
    "                time -= 1\n",
    "            if time > N_bins:\n",
    "                # raise ValueError('This should not happen')\n",
    "                break\n",
    "            for index in range(len(row) - 1):\n",
    "                value = row[index + 1]\n",
    "                if value == '':\n",
    "                    if mask_patient[index, time] == 0 and time - last_time > 0:\n",
    "                        # if last_time >= 0:\n",
    "                        #     data_patient[index, last_time + 1:time + 1] = data_patient[index, last_time]\n",
    "                        # else:\n",
    "                        if is_categorical_channel[id_to_channel[index]]:\n",
    "                            data_patient[index, last_time + 1:time + 1] = series_channel_info[id_to_channel[index]]['values'][normal_values[id_to_channel[index]]]\n",
    "                        else:\n",
    "                            data_patient[index, last_time + 1:time + 1] = float(normal_values[id_to_channel[index]])\n",
    "                else:\n",
    "                    mask_patient[index, time] += 1\n",
    "                    if is_categorical_channel[id_to_channel[index]]:\n",
    "                        data_patient[index, time] += series_channel_info[id_to_channel[index]]['values'][value]\n",
    "                    else:\n",
    "                        data_patient[index, time] += float(value)\n",
    "            last_time = time\n",
    "        data_patient = np.where(mask_patient > 0, data_patient / mask_patient, data_patient)\n",
    "        mask_patient = np.where(mask_patient > 0, 1, 0)\n",
    "        # assert np.count_nonzero(data_patient == np.nan) == 0\n",
    "        data_all.append(data_patient.transpose(-1, -2))\n",
    "        mask_all.append(mask_patient.transpose(-1, -2))\n",
    "print(len(data_all), len(mask_all), len(label_all), len(name_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0155376e-04 6.8193481e+01 2.3595384e-01 4.0348959e+00 6.2306409e+00\n",
      " 1.4745326e+01 4.8527946e+00 1.4117714e+02 9.4147171e+01 1.7033537e+02\n",
      " 8.6961792e+01 1.0695137e+02 2.2040630e+01 1.3308524e+02 3.8764061e+01\n",
      " 8.2098953e+01 7.7307324e+00] [2.0026991e-02 2.0938132e+02 1.2357162e-01 1.3062618e+00 1.9164379e+00\n",
      " 3.3472373e+00 1.6949662e+00 3.7657034e+02 3.7187466e+01 1.7419001e+01\n",
      " 1.3589072e+02 1.0969733e+03 1.3163010e+03 1.5891556e+02 1.1114523e+01\n",
      " 1.6920904e+01 2.0583203e+00]\n",
      "Observed Rate: 0.4376028588893591\n"
     ]
    }
   ],
   "source": [
    "data_all_concat = np.concatenate(data_all, axis=0)\n",
    "mean = np.mean(data_all_concat, 0)\n",
    "std = np.std(data_all_concat, 0)\n",
    "print(mean, std)\n",
    "data_normalized = [((data - mean.reshape(1, -1)) / std.reshape(1, -1)).tolist() for data in data_all]\n",
    "mask_all = [mask.tolist() for mask in mask_all]\n",
    "\n",
    "pickle.dump((data_normalized, label_all, mask_all, name_all), open('lengthofstay_normalized.pkl', 'wb'))\n",
    "\n",
    "cnt = 0\n",
    "cnt1 = 0\n",
    "for i in range(len(mask_all)):\n",
    "    for j in range(len(mask_all[i])):\n",
    "        cnt += sum(mask_all[i][j])\n",
    "        cnt1 += len(mask_all[i][j])\n",
    "print('Observed Rate:', cnt / cnt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
